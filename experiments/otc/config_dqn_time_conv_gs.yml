framework: tensorflow

env:
  env_module: envs.otc
  env_class: ObstacleTowerEnvWrapper
  additional_env_parameters:
    environment_filename: "/home/anton/devel/otc/ObstacleTower/obstacletower.x86_64"
    retro: True
    grayscale: True
#    id_parameter: "worker_id"
  is_gym: False
  obs_shapes: [[1, 84, 84], [1, 32, 32], [8]]  # list of lists
  obs_dtypes: ["uint8", "uint8", "float32"]
  history_length: [1, 16, 16]
  obs_is_image: False
#  obs_image_resize_to: [84, 84]
#  obs_image_to_grayscale: True  # used V from HSV
  action_size: 11
  action_postprocess:
    type: "argmax of softmax"
  action_remap_discrete: [
    0,  # no
    3,  # j
    6,  # cam left
    12,  # cam right
    18,  # forward
    21,  # jump + forward
    24,  # forw + cam left
    27,  # f + j + cam left
    30,  # f + cam right
    33,  # f + j + cam right
    36  # backward
  ]
  frame_skip: 2
  step_limit: 0
  agent_buffer_size: 10001
  reward_scale: 1.
  reinit_random_action_every: 5
  log_every_n_steps: 1000
  max_episode_length: 10000
  discrete_actions: True
#  reward_clip:
#    min: 0.95  # if reward > 0., for example turn 0.1 -> 0.5
#  stop_if_same_state_repeat: 30
#  render_with_cv2: True
#  render_with_cv2_resize: [400, 400]

server:
  seed: 42
  num_clients: 16
  experience_replay_buffer_size: 3200000
  use_prioritized_buffer: false
  train_every_nth: 1.
  start_learning_after: 10000
  target_critic_update_period: 1
#  target_critic_update_period: 2500
  show_stats_period: 10
  save_model_period: 50000
  ip_address: "0.0.0.0"
  client_start_port: 12977
  logdir: "logs/otc_33_model"
#  load_checkpoint: "logs/otc_31/model-1000000.ckpt"

algo_name: "dqn"

algorithm:
  n_step: 1
  gamma: 0.99
#  critic_grad_val_clip: 1.
  target_critic_update_rate: 0.001
#  target_critic_update_rate: 1.

critic:
  nn_engine: "keras"
  nn_arch:
    - input: 0
      name: "short-memory-1"
      layers:

        - type: "Scale"
          mult: 0.0078  # 2. / 255
          bias: -0.5

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Conv3D"  # 32 x 21 x 21 = 14112
          args:
            filters: 32
            kernel_size: [1, 8, 8]
            strides: [1, 4, 4]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

    - input: "short-memory-1"
      name: "short-memory-2"
      layers:

        - type: "Conv3D"  # 64 x 11 x 11 = 7744
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

    - input: "short-memory-2"
      name: "short-memory-3"
      layers:

        - type: "Conv3D"  # 128 x 6 x 6 = 4608
          args:
            filters: 128
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [4608]

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

    - input: "short-memory-1"
      name: "short-memory-1-fc"
      layers:

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [14112]

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

    - input: "short-memory-2"
      name: "short-memory-2-fc"
      layers:

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [7744]

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

    - input: ["short-memory-1-fc", "short-memory-2-fc", "short-memory-3"]
      name: "short-memory"
      layers:

        - type: "Concatenate"
          args:
            axis: 1

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

    - input: 1
      name: "long-memory"
      layers:

        - type: "Scale"
          mult: 0.0078  # 2. / 255
          bias: -0.5

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Conv3D"
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Conv3D"
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [16, 4096]

        - type: "Dense"
          args:
            units: 256
            activation: "relu"

        - type: "Reshape"
          args:
            target_shape: [4096]

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

    - input: 2
      name: "vec-obs"
      layers:
        - type: "Dense"
          args:
            units: 16
            activation: "relu"

        - type: "Reshape"
          args:
            target_shape: [256]

    - input: ["short-memory", "long-memory", "vec-obs"]
      name: "output"
      layers:

        - type: "Concatenate"
          args:
            axis: 1

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

        - type: "Dense"
          args:
            units: 11  # number of actions
            activation: "linear"
            kernel_initializer:
              class: "RandomUniform"
              module: "tensorflow.python.keras.initializers"
              args:
                minval: -0.003
                maxval: 0.003
            bias_initializer:
              class: "RandomUniform"
              module: "tensorflow.python.keras.initializers"
              args:
                minval: -0.003
                maxval: 0.003

critic_optim:
  schedule:
    - limit: 0  # of train ops
      lr: 0.0001

training:
  schedule:
    - limit: 0  # of train ops
      batch_size: 32

agents:
  - algorithm_id: 0
    agents:
      - agents_count: 1
        visualize: True

      - agents_count: 1
        exploration:
          type: "boltzmann"
          temp: 0.2

      - agents_count: 1
        exploration:
          type: "boltzmann"
          temp: 0.2
        env_params:
          start_level_inc: -1

      - agents_count: 1
        exploration:
          type: "e-greedy"
          random_prob: 0.2
#          type: "boltzmann"
#          temp: 0.2
        env_params:
          start_level_inc: -1


#      - agents_count: 1


#      - agents_count: 1
#        store_episodes: True
#
#      - agents_count: 1
#        store_episodes: True
#
#      - agents_count: 1
#        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
#
#      - agents_count: 1
#        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
#
#      - agents_count: 1
#        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
#
#      - agents_count: 1
#        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
