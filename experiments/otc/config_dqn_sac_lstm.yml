framework: tensorflow

env:
  env_module: envs.otc
  env_class: ObstacleTowerEnvWrapper
  additional_env_parameters:
    environment_filename: "/home/anton/devel/otc/ObstacleTower/obstacletower.x86_64"
    retro: True
#    id_parameter: "worker_id"
  is_gym: False
  obs_shapes: [[1, 84, 84], [1, 28, 28]]  # list of lists
  obs_dtypes: ["uint8", "uint8"]
  obs_is_image: True
#  obs_image_resize_to: [84, 84]
  obs_image_to_grayscale: True  # used V from HSV
  action_size: 10
  action_postprocess:
    type: "argmax of softmax"
  action_remap_discrete: [
    0,  # no
    3,  # j
    6,  # cam left
    12,  # cam right
    18,  # forward
    21,  # jump + forward
    24,  # forw + cam left
    27,  # f + j + cam left
    30,  # f + cam right
    33   # f + j + cam right
  ]
  frame_skip: 1
  step_limit: 0
  agent_buffer_size: 10001
  history_length: 8
  reward_scale: 1.
  reinit_random_action_every: 5
  log_every_n_steps: 1000
  max_episode_length: 10000
  discrete_actions: True
  reward_clip:
    min: 0.95  # if reward > 0., for example turn 0.1 -> 0.5
#  stop_if_same_state_repeat: 30
#  render_with_cv2: True
#  render_with_cv2_resize: [400, 400]

server:
  seed: 42
  num_clients: 16
  experience_replay_buffer_size: 3000000
  use_prioritized_buffer: false
  train_every_nth: 1.
  start_learning_after: 500
  target_critic_update_period: 1
#  target_critic_update_period: 2500
  show_stats_period: 10
  save_model_period: 5000
  ip_address: "0.0.0.0"
  client_start_port: 12977
  logdir: "logs/otc_19"
  #load_checkpoint: "logs/otc_15/model-245000.ckpt"

algo_name: "dqn_sac"

algorithm:
  n_step: 1
  gamma: 0.996
#  critic_grad_val_clip: 1.
  target_critic_update_rate: 0.001
#  target_critic_update_rate: 1.

critic:
  nn_engine: "keras"
  nn_arch:
    - input: 0
      name: "short-memory"
      layers:
        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Conv3D"
          args:
            filters: 32
            kernel_size: [1, 8, 8]
            strides: [1, 4, 4]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Conv3D"
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Conv3D"
          args:
            filters: 128
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [8, 4608]

        - type: "CuDNNLSTM"
          args:
            units: 256

    - input: 1
      name: "long-memory"
      layers:
        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Conv3D"
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Conv3D"
          args:
            filters: 64
            kernel_size: [1, 4, 4]
            strides: [1, 2, 2]
            padding: "same"
            data_format: "channels_first"
        - type: "Activation"
          args:
            activation: "relu"

        - type: "Permute"
          args:
            dims: [2, 1, 3, 4]

        - type: "Reshape"
          args:
            target_shape: [8, 3136]

        - type: "CuDNNLSTM"
          args:
            units: 256

    - input: ["short-memory", "long-memory"]
      name: "output"
      layers:

        - type: "Concatenate"
          args:
            axis: 1

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

        - type: "Dense"
          args:
            units: 512
            activation: "relu"

        - type: "Dense"
          args:
            units: 10  # number of actions
            activation: "linear"
            kernel_initializer:
              class: "RandomUniform"
              module: "tensorflow.python.keras.initializers"
              args:
                minval: -0.003
                maxval: 0.003
            bias_initializer:
              class: "RandomUniform"
              module: "tensorflow.python.keras.initializers"
              args:
                minval: -0.003
                maxval: 0.003

critic_optim:
  schedule:
    - limit: 0  # of train ops
      lr: 0.0001

training:
  schedule:
    - limit: 0  # of train ops
      batch_size: 64

agents:
  - algorithm_id: 0
    agents:
      - agents_count: 1
#        store_episodes: True
        visualize: True
#        env_params:
#          start_level_inc: -1  # from finished

#      - agents_count: 1
##        store_episodes: True
##        visualize: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
##        env_params:
##          start_level_inc: -1
#
#      - agents_count: 1
##        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.1
#        env_params:
#          start_level_inc: -1
#
#      - agents_count: 1
##        store_episodes: True
#        exploration:
#          type: "boltzmann"
#          temp: 0.2
#        env_params:
#          start_level_inc: -1
