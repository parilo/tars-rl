algo_name: "quantile_td3"
use_lstm_networks: True

actor:
  embedding_layers: []
  embedding_activations: []
  lstm_layers: [128]
  lstm_activations: ["tanh"]
  output_layers: [512, 512, 256, 256]
  output_layers_activations: ["relu", "relu", "relu", "relu"]
  output_activation: "tanh"
  layer_norm: False
  noisy_layer: False
  
  
critic:
  embedding_layers: []
  embedding_activations: []
  lstm_layers: [128]
  lstm_activations: ["tanh"]
  output_layers: [512, 512, 256]
  output_layers_activations: ["relu", "relu", "relu"]
  output_activation: "linear"
  # action_insert_block: 0
  num_atoms: 256
  layer_norm: False
  noisy_layer: False

actor_optim:
  schedule:
    - limit: 0
      lr: 0.0001
    - limit: 500000
      lr: 0.00005
    - limit: 1000000
      lr: 0.00005
    - limit: 1500000
      lr: 0.000025

critic_optim:
  schedule:
    - limit: 0
      lr: 0.0001
    - limit: 500000
      lr: 0.00005
    - limit: 1000000
      lr: 0.00005
    - limit: 1500000
      lr: 0.000025
      
training:
  schedule:
    - limit: 0
      batch_size: 256
    - limit: 500000
      batch_size: 256
    - limit: 1000000
      batch_size: 512
    - limit: 1500000
      batch_size: 512

algorithm:
  n_step: 1
  gamma: 0.99
  actor_grad_val_clip: 1.0
  target_actor_update_rate: 0.0025
  target_critic_update_rate: 0.005
