# Env
env:
  obs_size: 8
  action_size: 2
  frame_skip: 2

actor:
  hiddens: [256, 256]
  layer_fn: Linear
  bias: false
  norm_fn: null
  activation_fn: ReLU
  out_activation: Tanh

critic:
  hiddens: [256, 256]
  layer_fn: Linear
  bias: false
  norm_fn: null
  activation_fn: ReLU
  concat_at: 1
  n_atoms: 1

actor_optim:
  lr: 0.0003

critic_optim:
  lr: 0.0003

# Algorithm
algorithm:
  n_step: 1
  gamma: 0.99
  actor_grad_clip: 1.0
  target_actor_update_rate: 0.01
  target_critic_update_rate: 0.01

server:
  num_clients: 40
  batch_size: 256
  experience_replay_buffer_size: 100000
  use_prioritized_buffer: false
  use_synchronous_update: false
  train_every_nth: 1
  history_length: 3
  start_learning_after: 500
  target_critic_update_period: 1
  target_actor_update_period: 1
  show_stats_period: 100
  save_model_period: 10000
  init_port: 7577
